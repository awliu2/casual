\noindent \textcolor{Maroon}{\textbf{Objective}: In PSet 5 you used the \texttt{nswpsid.csv} data to estimate the \textcolor{ForestGreen}{propensity score (pscore)}, i.e., the probability that a unit is assigned to treatment as a function of their observed pre-determined characteristics (OPVs). You employed three estimation approaches: 1) OLS applied to a \textcolor{ForestGreen}{Linear Probability Model (LPM)}; 2) \textcolor{ForestGreen}{Lasso} also applied to a LPM; and, 3) \textcolor{ForestGreen}{Maximum Likelihood Estimation (MLE)} applied to a \textcolor{ForestGreen}{Logit Model}. In this PSet you use the Logit-based estimates of the pscore to estimate the ATT (of the offer of training) on post-training earning using four pscore-based matching approaches: 1) \textcolor{ForestGreen}{(Naive) Stratification Matching (SM)}; 2) \textcolor{ForestGreen}{Nearest-neighbor Matching (NNM)}; 3) \textcolor{ForestGreen}{Radius Matching (RM)}; and, 4) \textcolor{ForestGreen}{Kernel Matching (KM)}.} \\


\noindent \textcolor{Maroon}{\textbf{Background}: All matching approaches are predicated on the \textcolor{ForestGreen}{conditional independence assumption (CIA)} holding, i.e., on the assumption that \textit{conditional} on observed pre-determined characteristics (OPVs) treatment is as good as randomly assigned. When CIA holds, we can in theory exactly match (i.e., pair) treated and control units based on their OPVs, then estimate the treatment effect on the treated as the difference in the average outcome of the treated and the average outcome of the matched controls. This estimator will not be confounded by differences in OPVs because the \textcolor{ForestGreen}{matched sample} is by construction exactly balanced in the pre-treatment characteristics.} \\

\noindent \textcolor{Maroon}{In practice, matching exactly on OPVs runs into the \textcolor{ForestGreen}{curse of dimensionality problem} whenever there are many OPVs and/or some OPVs take many values. The statisticians Rosenbaum and Rubin (1983) showed that identification of TEs under CIA does not hinge on matching exactly on OPVs because imbalance in the OPVs matter only as far as it produces imbalance in the pscores. That is, matching units with different OPVs but the same pscore suffices to identify TEs. Formally, their result says that if CIA holds, then the potential outcomes are independent of treatment status conditional on the pscore.} \\

\noindent \textcolor{Maroon}{Rosembaum and Rubin's result suggests a matching estimator that matches controls to treated units based on the pscore rather than directly on the OPVs. In practice, matching exactly on the pscore may face the problem that there is no control unit with the same pscore value as a treated unit's (or viceversa). Econometricians have developed matching techniques to overcome this problem. These techniques differ in their implementation details but they share the same basic idea: instead of matching a control unit and a treated unit only when they have the exact same value of the pscore, they are matched if their pscores are ``sufficiently similar.'' The various techniques differ in terms of which matches they regard as ``sufficiently similar.'' As mentioned above, in this Pset you consider and implement four such techniques, i.e., SM, NNM, RM, and KM.} \\

\noindent \textcolor{Maroon}{Here is the gist of each technique: 
\begin{itemize}
\item \textbf{SM}: The idea of stratification is to divide the range of variation of the pscore into intervals such that within each interval there are both treated and control units and they have, \textit{on average}, the same pscore. In the limit, i.e., as we increase the number of intervals along with the sample size, SM matches exactly on the pscore. \item \textbf{NNM}: The idea of nearest-neighbor matching is to match a treated unit with the ``nearest'' M control units (M could be just 1 or a number larger than one). The control units matched to a treated unit are called the treated unit's ``nearest neighbors.'' In the limit, i.e., as we increase the sample size to infinity, NNM matches exactly on the pscore. 
\item \textbf{RM}: Each treated unit is matched with the control units whose pscore falls within a predefined neighborhood of the pscore of the treated unit. If the dimension of the neighborhood (i.e., the radius) is set very small, it is possible that some treated units are not matched because the neighborhood does not contain control units. On the other hand, the smaller the size of the neighborhood, the better the quality of the resulting matches. In the limit, i.e., as we decrease the radius along with increases in the sample size, RM matches exactly on the pscore. 
\item \textbf{KM}: Each treated unit is matched with a weighted average of all control units with weights that are inversely proportional to the difference between the pscore of the treated unit and that of the control units. In the limit, i.e., as we decrease the bandwith along with increases in the sample size, KM matches exactly on the pscore.
\end{itemize}
 In finite samples, the above four techniques reach different points on the frontier of the trade-off between quality and quantity of the matches, and none of them is a priori superior.}
