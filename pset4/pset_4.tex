% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{amsmath}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Problem Set 4},
  pdfauthor={Tessie Dong, Derek Li, Andi Liu},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Problem Set 4}
\author{Tessie Dong, Derek Li, Andi Liu}
\date{Due Jan 26th, 2024}

\begin{document}
\maketitle

\begin{center}
{\LARGE Part 1: Describe the Data (10 p)}
\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Fill Table \ref{tab:descriptive-stats}'s columns 5 and 6 using,
  respectively, the data in \texttt{nswpsid.csv} and in
  \texttt{nswcps.csv}.
  \textcolor{Gray}{\textbf{Notes}: You want to limit attention to observations with \texttt{treat=0}. You filled columns 3 and 4 in PSet 3.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load data}
\NormalTok{nswpsid }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"starter{-}files/nswpsid.csv"}\NormalTok{)}
\NormalTok{nswcps }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"starter{-}files/nswcps.csv"}\NormalTok{)}
\NormalTok{nswpsid\_treat0 }\OtherTok{\textless{}{-}}\NormalTok{ nswpsid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(treat }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\NormalTok{nswcps\_treat0 }\OtherTok{\textless{}{-}}\NormalTok{ nswcps }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(treat }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary\_cps }\OtherTok{\textless{}{-}} \FunctionTok{summarise\_all}\NormalTok{(nswcps\_treat0, }\FunctionTok{list}\NormalTok{(mean))}
\NormalTok{summary\_psid }\OtherTok{\textless{}{-}} \FunctionTok{summarise\_all}\NormalTok{(nswpsid\_treat0, }\FunctionTok{list}\NormalTok{(mean))}
\end{Highlighting}
\end{Shaded}

  \input{figures/table_descriptive_stats.tex}
\item
  Briefly comment on the completed Table \ref{tab:descriptive-stats}.
  \textcolor{gray}{\textbf{Hint}: Are the PSID-1 and CPS-1 samples "good" control groups?}

  \textbf{Answer:} I would argue that these samples are not the best
  control groups - this is mostly because many of the OPV covariates
  from the PSID and CPS exhibit large differences from the
  characteristics of the NSW sample. For example, the average age of the
  NSW sample is 25.82, while the average age of the PSID sample is 34.5,
  and there are large differences in income across the three samples.
  This suggests that the populations from which PSID and CPS were drawn
  are not very similar to the population of the NSW sample - making
  comparisons between treated individuals in the NSW sample and
  ``untreated'' individuals in the PSID and CPS samples less reliable,
  in our opinion.
\item
  Why do you think that Dehajia and Wahba constructed their
  ``observational datasets'' by pulling together the treated sample from
  NSW and a sample of individuals drawn from either the PSID or the CPS
  data?
  \textcolor{gray}{\textbf{Hint:} Both PSID and CPS include information on whether an individual enrolled in a training course during the previous 12 months. Thus, Dehajia and Wahba could have exploited exclusively observational variation in whether an individual enrolled in a training program. Why do you think that they chose not to follow this approach?}

  \textbf{Answer:} We believe that Dehajia and Wahba chose to pool the
  NSW and PSID/CPS datasets because they wanted to have a larger sample
  size to work with. This is because the NSW sample is relatively small,
  and the PSID/CPS samples are much larger. By pooling the NSW and
  PSID/CPS samples, Dehajia and Wahba are able to increase the sample
  size of their dataset. In addition, by analyzing samples drawn from
  different distributions (i.e.~PSID/CPS datasets), they could increase
  the generalizability of their results. In particular, the decision to
  have an experimental treatment group and observational control group
  rather than leveraging only observational data offers the potential to
  make some determination or estimate of a potential causal treatment
  effect. Using these two populations allows insights into how how
  training can act as a mechanism that drives changes in earnings,
  rather than only make claims about observational differences in the
  sample.
\end{enumerate}

\include{figures/table_reg_specs.tex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  (30 p) These questions pertain to the specification in expression
  (\ref{TCcomp}) thus you obtain the
  \textcolor{ForestGreen}{Treatment-Control Comparison (TCC) Estimator}
  of the treatment effect of the offer of training.\label{item:TCcomp}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    (8 p) Estimate \(\rho\). See table below for estimate of \(\rho\)
  \end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Run the regression}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(re78 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ treat, }\AttributeTok{data =}\NormalTok{ nswpsid)}

\CommentTok{\# Extract coefficients}
\NormalTok{coefficients }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(m1)}\SpecialCharTok{$}\NormalTok{coefficients[}\StringTok{"treat"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"Estimate"}\NormalTok{, }\StringTok{"Std. Error"}\NormalTok{)]}

\CommentTok{\# Get additional test statistics}
\NormalTok{test\_stats }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m1, }\AttributeTok{vcov. =} \FunctionTok{vcov}\NormalTok{(m1))}

\CommentTok{\# Combine into a data frame}
\NormalTok{result\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =}\NormalTok{ test\_stats[,}\StringTok{"Estimate"}\NormalTok{],}
                        \AttributeTok{Std\_Error =}\NormalTok{ test\_stats[,}\StringTok{"Std. Error"}\NormalTok{],}
                        \AttributeTok{t\_value =}\NormalTok{ test\_stats[}\DecValTok{2}\NormalTok{, }\StringTok{"t value"}\NormalTok{],}
                        \AttributeTok{Pr =} \FunctionTok{formatC}\NormalTok{(test\_stats[}\DecValTok{2}\NormalTok{, }\StringTok{"Pr(\textgreater{}|t|)"}\NormalTok{],}
                                    \AttributeTok{format =} \StringTok{"e"}\NormalTok{,}
                                    \AttributeTok{digits =} \DecValTok{3}\NormalTok{))}

\CommentTok{\# Create a table using kable}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(result\_df)}
\end{Highlighting}
\end{Shaded}

  \begin{longtable}[]{@{}lrrrl@{}}
  \toprule\noalign{}
  & Estimate & Std\_Error & t\_value & Pr \\
  \midrule\noalign{}
  \endhead
  \bottomrule\noalign{}
  \endlastfoot
  (Intercept) & 21553.92 & 303.6414 & -13.16871 & 2.033e-38 \\
  treat & -15204.78 & 1154.6143 & -13.16871 & 2.033e-38 \\
  \end{longtable}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
    (10 p) Compute \textcolor{ForestGreen}{heteroschedasticity-robust}
    SEs.
  \end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculate robust standard errors}
\NormalTok{robust\_se }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m1, }\AttributeTok{vcov. =}\NormalTok{ sandwich}\SpecialCharTok{::}\FunctionTok{vcovHC}\NormalTok{(m1, }\AttributeTok{type =} \StringTok{"HC0"}\NormalTok{))}

\CommentTok{\# Create a data frame for the table}
\NormalTok{result\_df2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =}\NormalTok{ robust\_se[,}\StringTok{"Estimate"}\NormalTok{],}
                        \AttributeTok{Robust\_Std\_Error =}\NormalTok{ robust\_se[,}\StringTok{"Std. Error"}\NormalTok{],}
                        \AttributeTok{t\_value =}\NormalTok{ robust\_se[,}\StringTok{"t value"}\NormalTok{],}
                        \AttributeTok{Pr =} \FunctionTok{formatC}\NormalTok{(robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Pr(\textgreater{}|t|)"}\NormalTok{],}
                                    \AttributeTok{format =} \StringTok{"e"}\NormalTok{,}
                                    \AttributeTok{digits =} \DecValTok{3}\NormalTok{))}

\CommentTok{\# Generate the table using kable}
\FunctionTok{kable}\NormalTok{(result\_df2)}
\end{Highlighting}
\end{Shaded}

  \begin{longtable}[]{@{}lrrrl@{}}
  \toprule\noalign{}
  & Estimate & Robust\_Std\_Error & t\_value & Pr \\
  \midrule\noalign{}
  \endhead
  \bottomrule\noalign{}
  \endlastfoot
  (Intercept) & 21553.92 & 311.6684 & 69.15658 & 1.506e-108 \\
  treat & -15204.78 & 655.6691 & -23.18971 & 1.506e-108 \\
  \end{longtable}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{2}
  \item
    (2 p) Verify that \(\hat{\rho}\) in \textbf{\ref{item:TCcomp-rho}}
    equals \((\overline{re78}^{D=1}-\overline{re78}^{D=0})\), i.e., the
    difference between the average post-training earnings of the treated
    and of the control individuals. This fact explains the name of the
    estimator, and is consistent with what you derived in previous
    Psets.\label{item:TCcomp-diff}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nswpsid\_treat1 }\OtherTok{=}\NormalTok{ nswpsid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(treat }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}

\NormalTok{estimate }\OtherTok{=} \FunctionTok{mean}\NormalTok{(nswpsid\_treat1}\SpecialCharTok{$}\NormalTok{re78) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(nswpsid\_treat0}\SpecialCharTok{$}\NormalTok{re78)}
\end{Highlighting}
\end{Shaded}

    The result in Q4a is -15204.78 which is equal to the difference
    between the average post-training earnings of the treated and of the
    control individuals, which is also equal to -15204.78.
  \item
    (10 p) Intuitively explain why the TCC approach may not deliver a
    credible estimate of the average effect of the treatment of
    interest.
    \textcolor{gray}{\textbf{Hint}: Use the result in  \textbf{\ref{item:TCcomp-diff}} to think about what this approach uses to proxy for the missing data, i.e., for the control units' mean of the potential outcome w/ treatment, and for the treated units' mean of the potential outcome w/out treatment.}\label{item:TCcomp-rho}

    \textbf{Answer:} The TCC approach uses the control group as a proxy
    for the missing potential outcome of the treatment group if they had
    not been treated, and vice versa. However, if the control group is
    not comparable with the treated group (i.e.~the samples are drawn
    from different populations), the proxy will be a poor estimator for
    population moments of interest. For instance, from the summary
    statistics provided, we can see that there are differences in
    characteristics such as age, education, and race between the treated
    and control groups. These differences suggest that the groups may
    not be comparable and thus the TCC approach may not deliver a
    credible estimate of the average effect of the treatment of
    interest.
  \end{enumerate}
\end{enumerate}

\pagebreak

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  (20 p) These questions pertain to the specification in expression
  (\ref{CFnc}) thus you obtain the
  \textcolor{ForestGreen}{Regression-Adjusted Treatment-Control Comparison (Adj. TCC) Estimator}
  of the treatment effect of the offer of training. \label{item:CFnc}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    (10 p) Add to the model estimated in \textbf{\ref{item:TCcomp}} the
    following OPVs as regression covariates: \texttt{age},
    \texttt{agesq}, \texttt{edu}, \texttt{nodegree}, \texttt{black},
    \texttt{hisp}, \texttt{re74}, and \texttt{re75}. Report
    \(\hat{\rho}\) and its heteroschedasticity-robust SE.
    \textcolor{gray}{\textbf{Programming Guidance:} Add column \texttt{agesq} (\texttt{age} squared) to your dataframe using, e.g., \texttt{dplyr::mutate( )}.}\label{item:CFnc-rho}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# add age squared to the dataframe}
\NormalTok{nswpsid }\OtherTok{\textless{}{-}}\NormalTok{ nswpsid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{agesq =}\NormalTok{ age}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(re78 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ treat }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ agesq }\SpecialCharTok{+}\NormalTok{ edu }\SpecialCharTok{+} 
\NormalTok{            nodegree }\SpecialCharTok{+}\NormalTok{ black }\SpecialCharTok{+}\NormalTok{ hisp }\SpecialCharTok{+}\NormalTok{ re74 }\SpecialCharTok{+}\NormalTok{ re75, }
            \AttributeTok{data =}\NormalTok{ nswpsid)}

\NormalTok{robust\_se }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m2, }\AttributeTok{vcov. =}\NormalTok{ sandwich}\SpecialCharTok{::}\FunctionTok{vcovHC}\NormalTok{(m2, }\AttributeTok{type =} \StringTok{"HC0"}\NormalTok{))}

\NormalTok{test\_stats }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m2, }\AttributeTok{vcov. =} \FunctionTok{vcov}\NormalTok{(m2))}
\NormalTok{result\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Estimate"}\NormalTok{],}
                        \AttributeTok{Std\_Error =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Std. Error"}\NormalTok{],}
                        \AttributeTok{t\_value =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"t value"}\NormalTok{],}
                        \AttributeTok{Pr =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Pr(\textgreater{}|t|)"}\NormalTok{])}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(result\_df, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{caption =} \StringTok{"OLS Regression Results"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

    \begin{longtable}[]{@{}rrrr@{}}
    \caption{OLS Regression Results}\tabularnewline
    \toprule\noalign{}
    Estimate & Std\_Error & t\_value & Pr \\
    \midrule\noalign{}
    \endfirsthead
    \toprule\noalign{}
    Estimate & Std\_Error & t\_value & Pr \\
    \midrule\noalign{}
    \endhead
    \bottomrule\noalign{}
    \endlastfoot
    217.944 & 766.444 & 0.284 & 0.776 \\
    \end{longtable}
  \item
    (10 p) Intuitively explain why the Adj. TCC approach may be regarded
    as an improvement over the TCC approach when it comes to credible
    identification/estimation of average treatment effects.
    \textbf{Answer:} Given the \texttt{nswpid.csv} dataset, we have a an
    experimental treatment group but a observational control group. When
    we consider how the average treatment effect is identified/esimated
    for an experiment, we are interested in \newline
    \[ATE = \mathbb{E}[Y_{i1} | D_i = 1] - \mathbb{E}[Y_{i0} | D_i = 1].\]
    \newline However, this cannot be identified as we do not have a good
    proxy for the population moment \(\mathbb{E}[Y_{i0} | D_i = 1]\),
    recognizing that it is likely that the treatment and control group
    are drawn from different populations in order to satisfy the
    randomization assumption.

    \par\medskip

    Notably, if we make the Selection on Observables assumption, that
    \(D_i\) and \(Y_i(d)\) are independent conditional on
    \(\boldsymbol{X}_i\) for every \(d\), where \(\boldsymbol{X}_i\) is
    a vector of variables that are observed in the data.

    We can then try to estimate / identify the average treatement effect
    on the treated as \newline
    \[ATT = \mathbb{E}[\mathbb{E}[Y_{i} |\boldsymbol{X}_i, D_i = 1] - \mathbb{E}[Y_{i} |\boldsymbol{X}_i, D_i = 0] \mid D_i = 1]\]
    \newline where such population moments can be estimated in the data.
  \end{enumerate}
\end{enumerate}

\pagebreak

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\item
  (20 p) Consider again the specification in expression (\ref{CFnc})
  estimated in \textbf{\textbf{\ref{item:CFnc}}}. Here you implement two
  procedures, as detailed below, to verify the
  \textcolor{ForestGreen}{``partialling-out'' interpretation} of OLS
  coefficients in MLRM.\label{item:CFnc-po}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    (8 p) Procedure A:

    \begin{enumerate}
    \def\labelenumiii{\roman{enumiii}.}
    \item
      (4 p) First Stage: Regress \texttt{treat} on a constant and the
      OPVs listed in \textbf{\ref{item:CFnc-rho}}; obtain the residuals.
      \textcolor{gray}{\textbf{Programming Guidance:} If you run \texttt{s1 $<$- lm(treat $\sim$ x1 + x2, data = dt)}, retrieve the residuals as \texttt{s1\$residuals}.}\label{item:CFnc-po-1ststep}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nswpsid\_const }\OtherTok{\textless{}{-}}\NormalTok{ nswpsid }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{constant =} \DecValTok{1}\NormalTok{)}
\CommentTok{\# regress treat on a constant and the OPVs listed in 5a}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(treat }\SpecialCharTok{\textasciitilde{}}\NormalTok{ constant }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ agesq }\SpecialCharTok{+}
\NormalTok{                 edu }\SpecialCharTok{+}\NormalTok{ nodegree }\SpecialCharTok{+}\NormalTok{ black }\SpecialCharTok{+} 
\NormalTok{                 hisp }\SpecialCharTok{+}\NormalTok{ re74 }\SpecialCharTok{+}\NormalTok{ re75, }
         \AttributeTok{data =}\NormalTok{ nswpsid\_const)}
\CommentTok{\# get residuals}
\NormalTok{resid\_m2 }\OtherTok{\textless{}{-}}\NormalTok{ m2}\SpecialCharTok{$}\NormalTok{residuals}
\end{Highlighting}
\end{Shaded}
    \item
      (4 p) Second Stage: Regress \texttt{re78} on a constant and the
      residuals from
      \textbf{\ref{item:CFnc-po-1ststep}}.\label{item:CFnc-po-2ndstep}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# regress re78 on a constant and the residuals from 6a}
\NormalTok{m3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(re78 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ constant }\SpecialCharTok{+}\NormalTok{ resid\_m2, }\AttributeTok{data =}\NormalTok{ nswpsid\_const)}

\NormalTok{robust\_se }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m3, }\AttributeTok{vcov. =}\NormalTok{ sandwich}\SpecialCharTok{::}\FunctionTok{vcovHC}\NormalTok{(m3, }\AttributeTok{type =} \StringTok{"HC0"}\NormalTok{))}
\NormalTok{result\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Estimate"}\NormalTok{],}
                        \AttributeTok{Std\_Error =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Std. Error"}\NormalTok{],}
                        \AttributeTok{t\_value =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"t value"}\NormalTok{],}
                        \AttributeTok{Pr =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Pr(\textgreater{}|t|)"}\NormalTok{])}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(result\_df, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{caption =} \StringTok{"OLS Regression Results"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

      \begin{longtable}[]{@{}rrrr@{}}
      \caption{OLS Regression Results}\tabularnewline
      \toprule\noalign{}
      Estimate & Std\_Error & t\_value & Pr \\
      \midrule\noalign{}
      \endfirsthead
      \toprule\noalign{}
      Estimate & Std\_Error & t\_value & Pr \\
      \midrule\noalign{}
      \endhead
      \bottomrule\noalign{}
      \endlastfoot
      217.944 & 1444.376 & 0.151 & 0.88 \\
      \end{longtable}
    \end{enumerate}
  \item
    (8 p) Procedure B:\label{item:CFnc-po-procB}

    \begin{enumerate}
    \def\labelenumiii{\roman{enumiii}.}
    \item
      First Stage: Same as
      \textbf{\ref{item:CFnc-po-1ststep}}.\label{item:CFnc-po-1ststep-bis}
    \item
      (4 p) First Stage: Regress \texttt{re78} on a constant and the
      OPVs listed in \textbf{\textbf{\ref{item:CFnc-rho}}}; obtain the
      residuals.\label{item:CFnc-po-3rdstep}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# regress re78 on a constant and the OPVs listed in 5a}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(re78 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ constant }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ agesq }\SpecialCharTok{+}
\NormalTok{                 edu }\SpecialCharTok{+}\NormalTok{ nodegree }\SpecialCharTok{+}\NormalTok{ black }\SpecialCharTok{+} 
\NormalTok{                 hisp }\SpecialCharTok{+}\NormalTok{ re74 }\SpecialCharTok{+}\NormalTok{ re75, }
         \AttributeTok{data =}\NormalTok{ nswpsid\_const)}
\CommentTok{\# get residuals}
\NormalTok{resid\_m4 }\OtherTok{\textless{}{-}}\NormalTok{ m4}\SpecialCharTok{$}\NormalTok{residuals}
\end{Highlighting}
\end{Shaded}
    \item
      (4 p) Second Stage: Regress the residuals from
      \textbf{\ref{item:CFnc-po-3rdstep}} on the residuals from
      \textbf{\ref{item:CFnc-po-1ststep-bis}}.\label{item:CFnc-po-4thstep}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# regress residuals from 6b on residuals from 6a}
\NormalTok{m5 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(resid\_m4 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ resid\_m2)}

\CommentTok{\# get coefficients}
\NormalTok{robust\_se }\OtherTok{\textless{}{-}}\NormalTok{ lmtest}\SpecialCharTok{::}\FunctionTok{coeftest}\NormalTok{(m5, }\AttributeTok{vcov. =}\NormalTok{ sandwich}\SpecialCharTok{::}\FunctionTok{vcovHC}\NormalTok{(m5, }\AttributeTok{type =} \StringTok{"HC0"}\NormalTok{))}
\NormalTok{result\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Estimate"}\NormalTok{],}
                        \AttributeTok{Std\_Error =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Std. Error"}\NormalTok{],}
                        \AttributeTok{t\_value =}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"t value"}\NormalTok{],}
                        \AttributeTok{Pr=}\NormalTok{ robust\_se[}\DecValTok{2}\NormalTok{, }\StringTok{"Pr(\textgreater{}|t|)"}\NormalTok{])}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(result\_df, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{caption =} \StringTok{"OLS Regression Results"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

      \begin{longtable}[]{@{}rrrr@{}}
      \caption{OLS Regression Results}\tabularnewline
      \toprule\noalign{}
      Estimate & Std\_Error & t\_value & Pr \\
      \midrule\noalign{}
      \endfirsthead
      \toprule\noalign{}
      Estimate & Std\_Error & t\_value & Pr \\
      \midrule\noalign{}
      \endhead
      \bottomrule\noalign{}
      \endlastfoot
      217.944 & 766.444 & 0.284 & 0.776 \\
      \end{longtable}
    \end{enumerate}
  \item
    (4 p) Verify that the estimates of the slope coefficient from
    \textbf{\ref{item:CFnc-po-2ndstep}} and
    \textbf{\ref{item:CFnc-po-4thstep}} are numerically identical to
    \(\hat{\rho}\) obtained in \textbf{\ref{item:CFnc-rho}}. Use this
    fact to give meaning to the expression ``partialling-out''
    interpretation of OLS in a MLRM.
    \textcolor{gray}{\textbf{Hint}: Think about what steps \textbf{\ref{item:CFnc-po-1ststep}} and \textbf{\ref{item:CFnc-po-3rdstep}} accomplish.}
  \end{enumerate}

  \textbf{Answer:} In 5a, we calculated \(\hat{\rho}\) to be 217.9. We
  obtained the same estiamte in 6(a)ii and 6(b)ii, verifying the
  partialling-out interpretation which tells us that that the estimate
  of the treatment effect obtained from this process is the amount of
  variation in the outcome variable that can be exclusively attributed
  to the treatment variable, after accounting for the variation
  explained by other covariates. From the background, we have the
  following form for MLRMs: \newline
  \[\text{MLRM: }y_i=\alpha+\beta_1 x_{1,i} + \dots + \beta_K x_{K,i} +u_i \text{ with } K>1.\]

  Verifying that the estimates of the slope coefficient from 6(a)ii and
  6(b)iii are numerically identical to the regression coefficient
  obtained in 5a serves as empirical evidence that the
  ``partialling-out'' interpretation is valid. This equality
  demonstrates that the effect of the treatment variable on the outcome
  variable is the same regardless of whether we control for the other
  variables by including them in the regression (as in 5a) or by
  partialling them out through the two-step residual process (as in 6(a)
  and 6(b)).
\end{enumerate}

\pagebreak

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\item
  (20 p) Consider the
  \textcolor{ForestGreen}{partially-linear specification} in expression
  (\ref{PLR}). Here you estimate \(\rho\) via the the
  \textcolor{ForestGreen}{Double Machine Learning (DML)} estimation
  procedure of Robinson (1988), as detailed below.\label{item:DML}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    (2 p) Install four R packages:
    \href{https://docs.doubleml.org/stable/intro/install.html#r-installing-doubleml}{\texttt{DoubleML}},
    \href{https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html}{\texttt{data.table}},
    \href{https://mlr3.mlr-org.com/}{\texttt{mlr3}}, and
    \href{https://mlr3learners.mlr-org.com/}{\texttt{mlr3learners}}.
  \end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"DoubleML"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"data.table"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"mlr3"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"mlr3learners"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{1}
  \item
    (2 p) If your data is not already a \texttt{data.table} object
    convert it.
    \textcolor{gray}{\textbf{Programming Guidance:} Assuming that your dataframe is called \texttt{df}, use \texttt{dt <- data.table::as.data.table(df)}. \texttt{data.table} is an extension of \texttt{data.frame} and allows for fast manipulation of very large data.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dt }\OtherTok{=}\NormalTok{ data.table}\SpecialCharTok{::}\FunctionTok{as.data.table}\NormalTok{(nswpsid)}
\end{Highlighting}
\end{Shaded}
  \item
    (2 p) Collect all the original OPVs in a list named, for example,
    \texttt{pretreat\_colnames}. Note: Henceforth when we refer to these
    OPVs in mathematical expressions we use the notation
    \(\mathbf{x}_{i}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pretreat\_colnames }\OtherTok{=} \FunctionTok{colnames}\NormalTok{(dt)[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{9}\NormalTok{)] }
\FunctionTok{print}\NormalTok{(pretreat\_colnames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "age"      "edu"      "black"    "hisp"     "married"  "re74"    
##  [7] "re75"     "u74"      "u75"      "nodegree" "agesq"
\end{verbatim}
  \item
    (2 p) Specify data and variables for the causal model by running the
    script:\label{item:dml-data}

\begin{verbatim}
dml_data_psid <- DoubleML::DoubleMLData$new(dt,
                        y_col = "re78",
                        d_cols = "treat",
                        x_cols = pretreat_colnames)
\end{verbatim}

    and look at the following object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dml\_data\_psid }\OtherTok{\textless{}{-}}\NormalTok{ DoubleML}\SpecialCharTok{::}\NormalTok{DoubleMLData}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(dt,}
                                            \AttributeTok{y\_col =} \StringTok{"re78"}\NormalTok{,}
                                            \AttributeTok{d\_cols =} \StringTok{"treat"}\NormalTok{,}
                                            \AttributeTok{x\_cols =}\NormalTok{ pretreat\_colnames)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dml\_data\_psid}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ================= DoubleMLData Object ==================
## 
## 
## ------------------ Data summary      ------------------
## Outcome variable: re78
## Treatment variable(s): treat
## Covariates: age, edu, black, hisp, married, re74, re75, u74, u75, nodegree, agesq
## Instrument(s): 
## No. Observations: 2675
\end{verbatim}
  \item
    (2 p) Suppress messages from the \texttt{mlr3} package by adding

    \texttt{lgr::get\textbackslash{}\_logger("mlr3")\textbackslash{}\$set\textbackslash{}\_threshold("warn")}

    to your script.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lgr}\SpecialCharTok{::}\FunctionTok{get\_logger}\NormalTok{(}\StringTok{"mlr3"}\NormalTok{)}\SpecialCharTok{$}\FunctionTok{set\_threshold}\NormalTok{(}\StringTok{"warn"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
  \item
    (2 p) Here you mimic the first stage of Procedure B in
    \textbf{\ref{item:CFnc-po-procB}}. Namely, you specify the model for
    the two regression functions
    \(l(\mathbf{x})=E[\texttt{re78}_i|\mathbf{x}_{i}=\mathbf{x}]\) and
    \(m(\mathbf{x})=E[\texttt{treat}_i|\mathbf{x}_{i}=\mathbf{x}]\). In
    \textbf{\ref{item:CFnc-po-procB}} you used a linear-in-parameter
    model and a priori decided which OPVs to include and which
    transformations to apply to the OPVs to include (e.g., you excluded
    \texttt{u74}, you used both \texttt{age} and \texttt{agesq}, you
    left as-is the other included OPVs). Instead here you do not a
    priori exclude any OPVs, and you use flexible models, which
    accommodate complex non-linearities. Run the
    script:\label{item:dml-first-stage-models}

\begin{verbatim}
# Specify a RF model as the learner model for l(x)=E[re78|X=x]
ml_l_rf <- mlr3::lrn("regr.ranger")

# Specify a RF model as the learner model for m(x)=E[treat|X=x]
ml_m_rf <- mlr3::lrn("classif.ranger")
\end{verbatim}
  \end{enumerate}

  The above script uses a
  \textcolor{ForestGreen}{Random Forest (RF) model} for both conditional
  expectations functions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ml\_l\_rf }\OtherTok{\textless{}{-}}\NormalTok{ mlr3}\SpecialCharTok{::}\FunctionTok{lrn}\NormalTok{(}\StringTok{"regr.ranger"}\NormalTok{)}
\NormalTok{ml\_m\_rf }\OtherTok{\textless{}{-}}\NormalTok{ mlr3}\SpecialCharTok{::}\FunctionTok{lrn}\NormalTok{(}\StringTok{"classif.ranger"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{6}
  \item
    (2 p) Here you initialize \& parametrize the model object which you
    later use to perform estimation. Run the script:

\begin{verbatim}
# Set seeds for cross-fitting
set.seed(3141)

# Set the DML specification
obj_dml_plr <- DoubleML::DoubleMLPLR$new(dml_data_psid, 
                                        ml_l = ml_l_rf, ml_m = ml_m_rf, 
                                        n_folds = 2,
                                        score = "partialling out",
                                        apply_cross_fitting = TRUE)
\end{verbatim}

    The above script: (i) utilizes the data object generated in
    \textbf{\ref{item:dml-data}}, namely \texttt{dml\_data\_psid}; (ii)
    utilizes the models for the first stage regressions picked in
    \textbf{\ref{item:dml-first-stage-models}}, namely
    \texttt{ml\_l\_rf} and \texttt{ml\_m\_rf}; (iii) specifies that we
    want to split the sample into 2 parts (\texttt{n\_folds = 2}), and
    (iv) that we want to use the ``partialling out'\,' approach to
    estimate causal impacts (\texttt{score = "partialling out"}), and
    (v) that we want to apply \textcolor{ForestGreen}{cross-fitting}
    (\texttt{apply\_cross\_fitting = TRUE}).\label{item:dml-model}
  \end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{3141}\NormalTok{)}

\NormalTok{obj\_dml\_plr }\OtherTok{\textless{}{-}}\NormalTok{ DoubleML}\SpecialCharTok{::}\NormalTok{DoubleMLPLR}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(dml\_data\_psid,}
                                        \AttributeTok{ml\_l =}\NormalTok{ ml\_l\_rf, }\AttributeTok{ml\_m =}\NormalTok{ ml\_m\_rf,}
                                        \AttributeTok{n\_folds =} \DecValTok{2}\NormalTok{,}
                                        \AttributeTok{score =} \StringTok{"partialling out"}\NormalTok{,}
                                        \AttributeTok{apply\_cross\_fitting =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{7}
  \item
    (2 p) Here you fit the DML model defined in
    \textbf{\ref{item:dml-model}}. Run the script:

\begin{verbatim}
obj_dml_plr$fit()
obj_dml_plr
\end{verbatim}
  \end{enumerate}

  At a high level the above script implements all of the following
  operations: (i) fits the two models for the first stage selected in
  \textbf{\ref{item:dml-first-stage-models}}, (ii) gets residuals, (iii)
  regresses the residuals for the outcome variables onto the residuals
  for the treatment indicator to obtain the DML estimate of \(\rho\) in
  expression (\ref{PLR}). Note: You specified \texttt{n\_folds = 2} and
  requested \texttt{apply\_cross\_fitting = TRUE} in
  \textbf{\ref{item:dml-model}} thus the 2-stage estimation procedure
  proceed as follows. First the entire data is split into two
  sub-samples, call them A and B (hence the term ``2 folds''). Sample A
  is used to fit the 1st stage models. These fitted models are used to
  compute residuals in sample B and these residuals are used to fit the
  2nd stage model using only data in sample B. Denote the resulting
  estimate \(\hat{\rho}_{AB}\). Then the samples are swapped (hence the
  term ``cross fitting'\,'). That is, sample B is used to fit the 1st
  stage models. Sample A is used to fit the 2nd stage model. Denote the
  resulting estimate \(\hat{\rho}_{BA}\). The DML estimate is the
  average of \(\hat{\rho}_{AB}\) and \(\hat{\rho}_{BA}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obj\_dml\_plr}\SpecialCharTok{$}\FunctionTok{fit}\NormalTok{()}
\NormalTok{obj\_dml\_plr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ================= DoubleMLPLR Object ==================
## 
## 
## ------------------ Data summary      ------------------
## Outcome variable: re78
## Treatment variable(s): treat
## Covariates: age, edu, black, hisp, married, re74, re75, u74, u75, nodegree, agesq
## Instrument(s): 
## No. Observations: 2675
## 
## ------------------ Score & algorithm ------------------
## Score function: partialling out
## DML algorithm: dml2
## 
## ------------------ Machine learner   ------------------
## ml_l: regr.ranger
## ml_m: classif.ranger
## 
## ------------------ Resampling        ------------------
## No. folds: 2
## No. repeated sample splits: 1
## Apply cross-fitting: TRUE
## 
## ------------------ Fit summary       ------------------
##  Estimates and significance testing of the effect of target variables
##       Estimate. Std. Error t value Pr(>|t|)
## treat    -603.6     1146.0  -0.527    0.598
\end{verbatim}

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \item
    (4 p) Take a look at the output, i.e., at the object
    \texttt{obj\_dml\_plr}. How does the DML estimate of average
    treatment effect compare to the estimates based on specifications
    (\ref{TCcomp}) and (\ref{CFnc})?

    \textbf{Answer:} It seems to be somewhere in between the other two
    estimators - its value of \(-603.6\) lies somewhere in between the
    TCC estimate of \(-15204.78\) and the Adj. TCC estimate of
    \(217.9\). It is difficult to comment on the validity of the DML
    estimate vs the other two specifications - all three of them are
    quite different than each other. However, the DML estimate is closer
    to the Adj. TCC estimate than the TCC estimate, which suggests that
    the DML estimate and the Adj. TCC estimate may be more reliable than
    the TCC estimate.
  \end{enumerate}
\end{enumerate}

\end{document}
