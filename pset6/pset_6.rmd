---
title: "Problem Set 6: Estimation of TEs Using Matching Methods"
author: "Tessie Dong, Derek Li, Andi Liu"
date: Due Feb 1st, 2024
output:
    pdf_document:
        keep_tex: true
        extra_dependencies: ['amsmath', 'optidef', 'accents','caption']
    html_document: default
colorlinks: true
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Change root.dir to match your working directory location
knitr::opts_knit$set(root.dir = "~/Documents/casual/pset6")
rmarkdown::pandoc_available()
library(tidyverse)
library(utils)
library(dplyr)
library(systemfit)
library(knitr)
library(readr)
```

\input{figures/premise.tex}

\newpage

## Part 1: Naive Stratification Matching on the Propensity Score (50 Points)
\input{figures/part1_background.tex}

1. (5 p) Let $\widehat{p}_i$ denote the Logit-based estimate of the pscore for unit $i$ which you obtained in PSet 5. Drop all sample units whose $\widehat{p}_{i}$ falls outside of the common support. Why may a researcher want to trim the sample in this way? How many control (treated) units do you drop? Are you surprised? In all subsequent questions you use the resulting \textcolor{ForestGreen}{trimmed sample}. \textcolor{gray}{\textbf{Programming Guidance:} Use \texttt{dplyr::filter()} to drop rows from a dataframe. Save the resulting dataframe as a new object; in our R script it is called \texttt{psid\_trimmed}.}\label{item:pscore-trim}

```{r}
load_data <- function(filename){
  dt <- data.table::as.data.table(
    readr::read_csv(filename,
                     col_names = TRUE,
                     col_types = readr::cols(
                       treat = readr::col_integer(),
                       age = readr::col_integer(),
                       edu = readr::col_integer(),
                       black = readr::col_integer(),
                       hisp = readr::col_integer(),
                       married = readr::col_integer(),
                       re74 = readr::col_double(),
                       re75 = readr::col_double(),
                       re78 = readr::col_double(),
                       u74 = readr::col_integer(),
                       u75 = readr::col_integer(),
                       nodegree = readr::col_integer()
                     ))
  )
  return(dt)
}
```

```{r}
filename_psid = "starter-files/nswpsid.csv"

dt_psid <- load_data(filename = filename_psid)

dt_psid[ , `:=` (agesq = age^2, edusq = edu^2, 
                 re74sq = re74^2, re75sq = re75^2, u74black=u74*black)]

pscore_formula = as.formula(treat ~ age + agesq + edu + edusq + 
                              married + nodegree + black + hisp + 
                              re74 + re75 + re74sq + re75sq + u74black)
```


```{r}
logit_obj <- stats::glm(pscore_formula, family=binomial(), data = dt_psid)
```

```{r}
dt_psid$logit_propensity <- predict(logit_obj, type="response")
```

```{r}
control <- dt_psid %>% filter(treat == 0)
treatment <- dt_psid %>% filter(treat == 1)
```

```{r}
p_cl = min(control$logit_propensity)
p_cu = max(control$logit_propensity)

p_tl = min(treatment$logit_propensity)
p_tu = max(treatment$logit_propensity)
```

```{r}
trimmed_df <- subset(dt_psid, logit_propensity >= 
              max(p_cl, p_tl) & logit_propensity <= min(p_cu, p_tu))
```

```{r}
length(control$logit_propensity)
- length((trimmed_df %>% filter(treat == 0))$logit_propensity)
```
```{r}
length(treatment$logit_propensity)
- length((trimmed_df %>% filter(treat == 1))$logit_propensity)
```

A researcher may want to trim the sample in this way because if we are interested in matching p-scores between treatment and control groups, dropping p-scores that are too low or too high allows the OPVs between the groups to be more balanced. This is because we are removing units with certain covariates that are unlikely or very likely to be treated. 

We dropped 1344 control units and 6 treated units. This is not surprising given the difference in the bounds, where $\hat{p}^{T,l}$ is almost $10e6$ times as large compared to $\hat{p}^{C,l}$ whilst the upper bounds are within $0.001$ of one another.

2. (5 p) Figure \ref{fig:propensity_vs_earnings} plots \texttt{re78} (the outcome metric) against $\widehat{p}_{i}$, separately for the treated and the control groups. Each panel also includes a curve that displays the fitted non-parametric regression of \texttt{re78} on $\widehat{p}_{i}$ i.e., a smoothed estimate of the mean of earnings conditional on the value of the pscore. Take for example the curve in the Treated panel, it connects earnings values constructed as follows. Pick a value of the pscore, e.g., $p=0.89567$. Identify the (for example) 10 closest pscore values in the treated sample. Using these 11 points, regress \texttt{re78} on a constant and the pscore values, giving more weight to the pscore values closest to $p=0.89567$. The implied fitted value of earnings at $p=0.89567$ is the value depicted on the curve.

a. Reproduce Figure \ref{fig:propensity_vs_earnings}. Test your understanding of the Loess smoothing method by varying the value of \texttt{span}. \textcolor{gray}{\textbf{Programming Guidance:} Use the script below which assumes that the trimmed dataframe is \texttt{trimmed\_df} and the Logit-based estimates are in column \texttt{pscore}. \texttt{ggplot2::ggplot()} produces a scatter plot. \href{https://ggplot2.tidyverse.org/reference/geom_smooth.html}{\texttt{geom\_smooth}}\texttt{(method = ``loess'', span = 0.5, method.args = list(degree = 1))} overlays a smoothed curve: (i) the \texttt{method} argument picks the LOWESS (LOcally WEighted Scatter-plot Smoother) smoothing method, i.e., the R function \href{https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/loess}{\texttt{stats::loess()}}; (ii) the \texttt{span} argument indicates the proportion of the total number of points that contribute to each local fitted value; (iii) the \texttt{method.args} argument lists additional arguments passed on to the function \texttt{stats::loess()}, in particular \texttt{degree = 1} picks a polynomials of degree 1 (which is just a line). Here is a \href{https://ggplot2.tidyverse.org/reference/geom_smooth.html}{link} to some examples.}
    
```{r}
# Draw scatter plot of post-intervention earnings
# and the Logit-based pscore, by group;
# overlay smooth local regression line.
plot_df <- trimmed_df %>%
dplyr::filter(re78 < 20000) %>% # drop outliers for plotting purposes
dplyr::mutate(treat = factor(ifelse(treat == 1, "Treated", "Control")))
p <- ggplot2::ggplot(plot_df, ggplot2::aes(x = logit_propensity, y = re78)) +
ggplot2::facet_grid(~treat) +
ggplot2::geom_point() + 
ggplot2::scale_y_continuous(breaks=seq(0,20000,by=1000)) +
ggplot2::geom_smooth(method = "loess", formula = y ~ x, span = 0.5, 
                                        method.args = list(degree = 1)) +
ggplot2::ylab("Real Earnings in 1978") +
ggplot2::xlab("Estimated Propensity Score") +
ggplot2::labs(caption = "Data Source: NSW-PSID1.") +
theme_bw()

p
```

b. (3 p) Can you eyeball estimate\textbf{s} of the TE of the offer of training from these figures? Explain.  
    
        From the two smoothed cruves on the graphs, we can roughly eyeball that the TEs are not homogenous across different pscores. For example, we eyeball that for pscores < 0.5, the estimates of the TE are roughly 0 as there does not seem to be a significant difference between the real earnings in '78 for the control and treated groups. However, for pscores that are > 0.5, we eyeball that the estimates of TE are positive (e.g. for pscore = 0.75, the TE seems to be ~1.5k), implying that there is a positive impact of the training offer on real earnings in '78 for those pscores.

3. (40 p) We can do better than eyeballing TEs. You are now ready to implement \textcolor{ForestGreen}{stratification matching}.
    
a. (5 p) Add a column to your dataframe called \texttt{stratum} that takes values from 1 to 10 corresponding to 10 equally spaced intervals with \texttt{stratum=1} if $0<\widehat{p}_{i}\leq 0.1$, \texttt{stratum=2} if $0.1<\widehat{p}_{i}\leq 0.2$, and so on.\footnote{\textit{Strata} is the plural of \textit{stratum}, both are Latin words.} What is the distribution of control and treated observation across strata? Are all strata \textcolor{ForestGreen}{populated}? \textcolor{gray}{\textbf{Programming Guidance:} To bin the values of a column, use the R base function \href{https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/.bincode( )}{\texttt{.bincode}} with break points at 0, 0.1, 0.2 etc. up to 1. To add a column to a dataframe, use \texttt{dplyr::mutate( )}. To produce summary statistics by group, use \texttt{dplyr::group\_by( )}, and pipe the result to \texttt{dplyr::summarize( )}. In our R script we produce the following summary statistics within each stratum: count of treated units, count of control units, minimum pscore value, maximum pscore value.}
```{r}
b <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)

trimmed_df <- dplyr::mutate(trimmed_df, 
                            stratum = .bincode(trimmed_df$logit_propensity, b))

strata <- trimmed_df %>% 
  dplyr::group_by(trimmed_df$stratum) %>% 
  dplyr::summarize(count_of_treated = length(which(treat == 1)), 
                  count_of_control = length(which(treat == 0)), 
                  min_pscore = min(logit_propensity), 
                  max_pscore = max(logit_propensity))

knitr::kable(strata)
```

The distribution of control and treated observation across strata is shown in the table above. We see that within stratum 9 (between 0.8 and 0.9), there are no control units. Besides that stratum, all others are populated by both treated and contrl units. We also observe that there is a significantly higher concentration of control units within the 1st stratum. 

b. (25 p) Test that the average of each pretreatment variable is the same for treated and control units within each stratum: the pre-treatment variables are \texttt{age, edu, married, nodegree, black, hisp, re74, re75, u74black}. Can you think of a reason why you may want to run this test? Comment on your findings. \textcolor{gray}{\textbf{Programming Guidance:} Use SUR estimation as you did in PSet 3, but now do this within each stratum. Skip strata that do not have both control and treated units. Within some of the strata, some of the pre-treatment variables are perfectly collinear or do not vary. This causes \texttt{systemfit::systemfit( )} to produce an error. To avoid it, you first identify which of the pre-determined variables exhibit the problem, then you exclude them from the list of dependent variables of the SUR system, then you invoke \texttt{systemfit::systemfit( )}. To loop over strata, use the \texttt{for} loop: \texttt{for(stratrum in 1:10) \{ $<$ script $>$\}}. Below is a user-defined function that returns the names of the collinear columns in a dataframe, feel free to use it:}

  **Solution:** We may want to run this test to ensure that the pretreatment variables are balanced across the treated and control groups within each stratum. This is important because we want to ensure that the strata are balanced and that the treatment effect is not confounded by differences in observables - in other words, we want to ensure that within a specific range of propensity scores, we have similar distributions of pretreatment variables between the treated and control groups. If this were not the case, we may want to consider if some amount of confounding or selection bias is present in our sample - for example, if we observe that within a specific stratum with $0.1 < p < 0.2$, the treated group is significantly older than the control group, we may want to consider if the likelihood of being treated is correlated with age, and if so, whether the treatment effect is confounded by age.

  We see below that in general, our OPVs remain balanced across strata, and there seems to be no trends in the differences between the treated and control groups across the strata. This is a good sign - it suggests that the treatment selection has not been confounded by the pretreatment variables, and thus there are no signs that the treatment effect is confounded by differences in observables.

```{r}
# Declare a function that identifies perfectly collinear covariates.
# Note: this fnc is roughly equivalent to _rmcoll in STATA.
rmcoll <- function(df, colnames = names(df)) {
  # Arguments:
  # - df: A data frame.
  # - colnames: A list of column names.
  # Returns:
  # A list with the column names of collinear variables.
    df_ <- df %>% dplyr::select(one_of(colnames))
    cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
    return(names(cc)[is.na(cc)])
} # end fnc rmcoll
```

```{r}
stratum_tables <- list()
for(stratum_i in 1: 10){
  subset <- trimmed_df %>% filter(stratum == stratum_i)
  # Skip strata that do not have either no control or no treated units
  if (sum(subset$treat == 0) <= 0 || 
      sum(subset$treat == 1) <= 0) {
    next
  }
  
  opvs <- c("age", "edu", "married", "nodegree", "black",
            "hisp", "re74", "re75", "u74black")
  
  non_collinear <- setdiff(opvs, rmcoll(subset, opvs))

  sur_system <- list()
  for (v in non_collinear) {
    sur_system[[v]] <- formula(paste(v, "~ treat"))
  }
  # null_system <- map(vars, function(x) formula(paste(x, "~ 1")))
  sur_fit <- systemfit::systemfit(formula=sur_system, data=subset, method="SUR")
  
  coeffs <- (summary(sur_fit)$coefficients)
  
  # keep only _treat_ coefficients
  coeffs <- coeffs[grep("treat", rownames(coeffs)), ]
  # generate a table of each opv's estimate, std. error, and p-value
  tab_sur <- data.frame(opv = rownames(coeffs),
                        stratum = stratum_i,
                        estimate = coeffs[, "Estimate"], 
                        std_error = coeffs[, "Std. Error"], 
                        p_value = coeffs[, "Pr(>|t|)"])
  
  stratum_tables <- append(stratum_tables, list(tab_sur))
}
```

```{r, echo=FALSE}
bound_df <- bind_rows(stratum_tables)
knitr::kable(bound_df, row.names = FALSE)
```

c. (10 p) Let $N_{s}^{T}$ denote the number of treated units in stratum $s$ with $s=1,...,10$. Let $N^{T}=\sum_{s=1}^{10}N_{s}^{T}$. Let $\overline{re78}_{s}^{1}$ (respectively, $\overline{re78}_{s}^{0}$) denote average post-treatment earnings for treated (respectively, control) units in stratum $s$. Estimate the ATT of the offer of training using stratification matching estimator (\ref{strata_ATT}). Explain in plain English why this is an estimator of the ATT. \textcolor{gray}{\textbf{Programming Guidance:} To compute a weighted average use \href{https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/weighted.mean}{\texttt{stats::weighted.mean( )}} where you let the argument \texttt{w} be a vector with the counts of treated units in each stratum. Verify that you get \$1,563.}\label{item:naive-ATT-estimate}

    
    \begin{equation}
    \widehat{ATT}^{SM}=\sum_{s=1}^{10}\left( \frac{N_{s}^{T}}{N^{T}}\right) \left( \overline{re78}_{s}^{1}-\overline{re78}_{s}^{0}\right) 
    \text{.}\label{strata_ATT}
    \end{equation}
    
    
```{r}

te <- c()
w <- c()

for(i in 1: 10) {
  
  if(i == 9){
    next
  }
  
  stratum_df <- trimmed_df %>% filter(stratum == i)
  stratum_treat <- stratum_df %>% filter(treat == 1)
  stratum_control <- stratum_df %>% filter(treat == 0)
  re78_1bar <- mean(stratum_treat$re78)
  re78_0bar <- mean(stratum_control$re78)
  stratum_te <- re78_1bar - re78_0bar
  
  te <- c(te, stratum_te)
  
  weight <- nrow(stratum_treat)
  w <- c(w, weight)
}

att_sm <- round(weighted.mean(te, w/sum(w)), digits = 2)
att_sm


```
  
From above, we see that our calculated estimate of the ATT to be \$1562.73 which rounds to \$1563, as desired. This is an estimate of the ATT because we are computing the treatment effect within the sub-population of the treated individuals. We can think of each calculate TE within stratum as a CATE (conditional upon the stratum), and then we performed a weighted sum of these CATEs (weighed by proportion of treated within each stratum : total treated in the sample), which is by definition the ATT estimator.

## Part 2: Fancier Matching On the PScore (50 Points)

\input{figures/part2_background.tex}
\newpage

4. (6 p) Denote the outcome variable by $y$. Show that under unconditional random assignment (RA), $\widehat{ATT}^{m}=\overline{y}^{1}-\overline{y}^{0},$ $\forall m\in \left\{ NNM,RM,KM\right\}$. That is, if there are no observable confounders, all three estimators reduce to the Treatment-Control Comparison estimator. \textcolor{gray}{\textbf{Hint:} Assign treatment by the flip of a balanced coin, i.e., let $\widehat{p}_{i}=0.5$ for all $i$. Then, simplify expressions (\ref{ATT_m}) and (\ref{w_ij}). Do read carefully the background information presented above.}

5. (9 p) Show that $\widehat{ATT}^{m}$ in expression (\ref{ATT_m}) rewrites as:

\begin{equation} \label{ATT_m_bis}
\widehat{ATT}^{m} =\overline{y}^{1}-\overline{y}_{m}^{0} \ \forall m\in \left\{ NNM,RM,KM\right\},
\end{equation}

\noindent where:

\begin{equation}\label{ATT_m_bis_w}
\overline{y}^{1} =\frac{1}{N^{T}}\sum_{j \in T}y_{j}, \text{     and      }  \overline{y}_{m}^{0} =\frac{1}{N^{C}}\sum_{j \in C}\pi_{j}^{m}y_{j}.
\end{equation}

\noindent Use expression (\ref{ATT_m_bis}) to describe in plain English the essence of each matching approach.  \textcolor{gray}{\textbf{Hint:} Find the expression for $\pi _{j}^{m}$ in expression (\ref{ATT_m_bis_w}) for each $m\in \left\{NNM,RM,KM\right\} $}.


6. (3 p) With the trimmed sample from Part 1, produce the 1:1 NNM estimate of ATT using \href{https://www.rdocumentation.org/packages/Matching/versions/4.9-6/topics/Match}{\texttt{Matching::Match( )}} from the package \href{https://cran.r-project.org/web/packages/Matching/Matching.pdf}{\texttt{Matching}}. Verify that it coincides with that presented in Table \ref{tab:Tab25-4_2}. \textcolor{gray}{\textbf{Note:} Table \ref{tab:Tab25-4_2} also reports estimates based on 3 other PSM approaches (you are not asked to implement them). ``Adaptive Stratification'' is a refinement of the ``Naive Stratification'' approach that you implemented in Part 1: strata are created iteratively (as opposed to being fixed ahead of time) so as to ensure balance within each stratum.}  \textcolor{gray}{\textbf{Programming guidance:} \texttt{Matching::Match()} takes 3 dataframes as inputs, \texttt{Y}, \texttt{Tr} and \texttt{X}. \texttt{Y} and \texttt{Tr} are columns \texttt{re78} and \texttt{treat} respectively in your dataframe, and \texttt{X} is the column that stores the Logit estimates of the pscore because you want to match on the estimated pscore. Specify \texttt{M=1} and \texttt{estimand=``ATT''} so that you estimate ATT using 1:1 matching. Use \texttt{summary()} on the object returned, which is a list of 23 elements.} \label{item:estimate-att-ncs}


\begin{table}[h]
\centering
\begin{tabular}{ccc}
\hline \hline
\textbf{Matching Estimator} & \textbf{Estimate (\$/year)} & \textbf{SE (\$/year)} \\ \hline
1:1 Nearest-Neighbor Matching with Replacement (NNM)       &  490.39 & 1,929.6  \\
Radius Matching with $r=0.0001$ (RM)  &  -5,546.139 &  4,614.773 \\
Gaussian Kernel Matching (KM)        &  1,537.947 & 861.329  \\ 
Adaptive Stratification Matching     &  2,208.603 &  855.168 \\ \hline
\end{tabular}
\caption{Estimates of ATT based on four pscore-matching estimators.}
\label{tab:Tab25-4_2}
\end{table}

```{r}
Y <- trimmed_df$re78
Tr <- trimmed_df$treat
X <- trimmed_df$logit_propensity

matched <- Matching::Match(Y,Tr,X,M=1,estimand="ATT")

nnm_df <- data.frame(matched[c('est', 'se')])
colnames(nnm_df) <- c('NNM Estimate', 'NNM Std. Error')

summary_matched <- summary(matched)

knitr::kable(nnm_df)

```


7. (16 p) Consider the \textcolor{ForestGreen}{matched data}, i.e., the collection of pairs such that each pair is a treated unit and a matched control.

a. (2 p) How many treated units are paired with at least one control unit? 
    
```{r}

num_treated_paired = length(unique(matched$index.treated))
num_treated_paired

```
    
  **Solution:** 179 treated units are paired with at least one control unit.
    
    
b. (2 p) How many treated units are paired with exactly one control unit? 
    
  **Solution:** 179 treated units are paired with at least one control unit. Since we set M=1 in the Match function, each treated unit is matched with exactly one control unit. Therefore, the number of treated units paired with exactly one control unit would be the same as the number of treated units that were paired as in part (a).

c. (2 p) What percentage of control units serve as a match to at least one treated unit? 
    
```{r}
num_control_matched = length(unique(matched$index.control))
total_control_units = sum(Tr == 0)
control_matched = (num_control_matched / total_control_units) * 100
control_matched
```
    
  **Solution:** About 46.68\% of control units serve as a match to at least one treated unit.
    
d. (2 p) Take the treated units that are paired with exactly 1 control unit, how many distinct control units serve as matches to these treated units? Are you surprised?
    
```{r}
num_distinct_controls_for_treated = length(unique(matched$index.control))
num_distinct_controls_for_treated 

```
    
**Solution:** 535 distinct control units serve as matches to these treated units. Initially, this was surprising because all the treated units are paired with exactly one control unit, but there are more matched control units than matched treated units.


e. (2 p) The algorithm matches one treated unit with 209 distinct control units. How do you make sense of this?
    
**Solution:** This can happen because the many control units might have identical or very similar pscores relative to a treated unit. The matching algorithm handles ties by matching the treated unit to all equally good control matches (with the same pscore), this could result in a large number of matches for a single treated unit.
    
f. Make sense of the line ``\texttt{Matched number of observations (unweighted). 700}'' in Figure \ref{fig:nnm_output}. 
        \begin{figure}[h]
        \centering
        \captionsetup{width=.6\textwidth}
        \includegraphics[width=0.4\textwidth]{figures/q7_f.png}
        \caption{Snapshot of output produced by running \texttt{symmary()} on the object returned by \texttt{Matching::Match()} in \textbf{\ref{item:estimate-att-ncs}}.}
        \label{fig:nnm_output}
        \end{figure}
        
**Solution:** This line means that there are 700 matched pairs. This does not take into account that one treated unit might be matched with multiple control units.

g. (2 p) Use the matched data to ``manually'' compute the ATT estimate. 
h. (2 p) Run \texttt{Matching::Match()} with \texttt{ties = FALSE}. Why do you get ``\texttt{Matched number of observations (unweighted). 179}?''

```{r}

matched_notie <- Matching::Match(Y,Tr,X,M=1,estimand="ATT",ties = FALSE)
(summary(matched_notie))

```

**Solution:** I get "Matched number of observations (unweighted). 179" because setting ties = FALSE instructs the  algorithm not to match treated units to more than one control unit when there are ties in the matching criterion (e.g. distance based on propensity score). So we get exactly 179 matched pairs.

\textcolor{gray}{\textbf{Programming Guidance}: Explore the list returned by \texttt{Matching::Match()}, in particular the named elements \texttt{mdata}, \texttt{index.treated}, \texttt{index.control} and \texttt{weights}.} \textcolor{gray}{\textbf{Hint}: Use \texttt{names()} to see the elements in the list returned by \texttt{Matching::Match()}. Feel free to use Table \ref{tab:matched-set-ds} to check on your work on the matched data. The matched data shall be a dataframe with 700 rows, because there are 700 matched pairs. We recommend that you have as columns the following: an index counter for the treated unit in the pair, an index counter for the control unit in the pair, the pscore value for the treated unit in the pair, the pscore value for the control unit in the pair, the outcome (namely \texttt{re78}) for the treated unit in the pair, the outcome for the control unit in the pair, the weight for the control unit in the pair. With this information you can answer all the questions (and more).}

\newpage 
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{\texttt{num\_matches}} & \textbf{\texttt{num\_treated}} & \textbf{\texttt{min\_pscore}} & \textbf{\texttt{avg\_pscore}} & \textbf{\texttt{med\_pscore}} & \textbf{\texttt{max\_pscore}} \\ \hline
209 & 1 & 0.000652575 & 0.000652575 & 0.000652575 & 0.000652575 \\ \hline
129 & 1 & 0.003290713 & 0.003290713 & 0.003290713 & 0.003290713 \\ \hline
70 & 1 & 0.005570029 & 0.005570029 & 0.005570029 & 0.005570029 \\ \hline
35 & 2 & 0.007592412 & 0.007776318 & 0.007776318 & 0.007960224 \\ \hline
9 & 1 & 0.055467716 & 0.055467716 & 0.055467716 & 0.055467716 \\ \hline
7 & 1 & 0.028241882 & 0.028241882 & 0.028241882 & 0.028241882 \\ \hline
5 & 2 & 0.07015485 & 0.082214016 & 0.082214016 & 0.094273183 \\ \hline
4 & 2 & 0.046380154 & 0.061290142 & 0.061290142 & 0.076200129 \\ \hline
3 & 3 & 0.133671949 & 0.688292564 & 0.965164821 & 0.966040924 \\ \hline
2 & 14 & 0.127383235 & 0.369653196 & 0.336881761 & 0.949418099 \\ \hline
1 & 151 & 0.141036436 & 0.753198139 & 0.900426437 & 0.972637597 \\ \hline
\end{tabular}

\caption{Descriptive statistics for the matched data. The column \texttt{num\_matches} lists the (distinct) count of control units matched to a treated unit, from largest to smallest. The column \texttt{num\_treated} reports the number of treated units with the corresponding count of matched controls. The sum of this column is 179, i.e., the number of treated units in the trimmed sample. The sum of the row-wise product of the first two columns is 700. The remaining columns present min/average/median and max value of the pscore for the treated units with the corresponding count of matched controls. Example A: 1 treated unit is matched to 209 distinct control units, this unit's pscore is 0.000652575. Example B: 14 treated units are each matched to exactly two control units, the maximum pscore among these 14 units is 0.949418099. Example C: 151 treated units are each matched to exactly one control unit, the average of these treated units' pscores is 0.753198139.}
\label{tab:matched-set-ds}
\end{table}


8. (10 p) Use \texttt{Matching::MatchBalance()} to document balance in the covariates (those in the Logit specification for the pscore model) before and after matching. Comment on your findings: a) Are covariates more/less balanced after matching? b) Are covariates in the matched sample sufficiently balanced to make you trust that the NNM estimator is not confounded by differences in observables? \textcolor{gray}{\textbf{Programming guidance:} Use 500 bootstrap replication, i.e., set \texttt{nboots=500}. Say that you name \texttt{nnm\_balance} the object (a list of lists) returned by the call to \texttt{Matching::MatchBalance()}. Apply \texttt{names()} to see the named element of the list. To check that your implementation is correct: the averages of \texttt{age} in the trimmed sample before matching and in the matched sample (i.e., after matching) are, respectively:
    \begin{itemize}
    \item \texttt{nnm\_balance\$BeforeMatching[[age\_loc]]\$mean.Tr = 25.76536}, 
    \item \texttt{nnm\_balance\$BeforeMatching[[age\_loc]]\$mean.Co = 30.96161},
    \item \texttt{nnm\_balance\$AfterMatching[[age\_loc]]\$mean.Tr = 25.76536},
    \item \texttt{nnm\_balance\$AfterMatching[[age\_loc]]\$mean.Co = 26.1724}
    \end{itemize}
where, in our script, \texttt{age\_loc} is the number that identifies the location of the information for the covariate \texttt{age}.}

9. (6 p) The estimate of ATT based on the experimental data is \$1,794 with SE \$633 (see PSet 3). Consider the estimates of ATT in Table \ref{tab:Tab25-4_2}: What are the takeaways? Taking inspiration from Imbens (2015)'s recommendations, are there actions you may want to take to gain more confidence in your ability to learn about the true causal impact of the offer of training via matching when you only have access to observational data?

\newpage
\begin{figure}[!htb]
\centering
  \includegraphics[width=0.9\textwidth]{figures/figures_end.png}
  \caption{Scatter plot of \texttt{re78} against the Logit-based $\widehat{p}_{i}$ estimates, separately for the treated and the control group. Each panel also includes a fitted non-parametric regression of \texttt{re78} on $\widehat{p}_{i}$ (blue line).}
  \label{fig:propensity_vs_earnings}
\end{figure}
